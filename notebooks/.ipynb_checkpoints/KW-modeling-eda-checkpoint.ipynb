{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Exploratory-Modeling\" data-toc-modified-id=\"Exploratory-Modeling-1\">Exploratory Modeling</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Scaling\" data-toc-modified-id=\"Scaling-1.0.1\">Scaling</a></span></li><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-1.0.2\">Regression</a></span></li><li><span><a href=\"#Tree-Based-Regression\" data-toc-modified-id=\"Tree-Based-Regression-1.0.3\">Tree Based Regression</a></span></li><li><span><a href=\"#Feature-Importance\" data-toc-modified-id=\"Feature-Importance-1.0.4\">Feature Importance</a></span></li><li><span><a href=\"#Selecting-the-Best-Model\" data-toc-modified-id=\"Selecting-the-Best-Model-1.0.5\">Selecting the Best Model</a></span></li><li><span><a href=\"#Parameter-Tuning\" data-toc-modified-id=\"Parameter-Tuning-1.0.6\">Parameter Tuning</a></span></li><li><span><a href=\"#Scitkit-learn-Random-Forest\" data-toc-modified-id=\"Scitkit-learn-Random-Forest-1.0.7\">Scitkit-learn Random Forest</a></span></li></ul></li><li><span><a href=\"#Keras-Regression\" data-toc-modified-id=\"Keras-Regression-1.1\">Keras Regression</a></span></li><li><span><a href=\"#Pytorch-Regression\" data-toc-modified-id=\"Pytorch-Regression-1.2\">Pytorch Regression</a></span></li></ul></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-2\">Classification</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Tree-based-Classification\" data-toc-modified-id=\"Tree-based-Classification-2.0.1\">Tree-based Classification</a></span></li><li><span><a href=\"#Neural-Net-Classification\" data-toc-modified-id=\"Neural-Net-Classification-2.0.2\">Neural Net Classification</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('collin_data/*')\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeDf(path):\n",
    "    \n",
    "    df = pd.read_csv(path).reset_index()\n",
    "    df.drop(\" pill_count\", axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetaInfo(path):\n",
    "    \n",
    "    pill_count = path.split(\"_\")[-1].split(\".\")[0]\n",
    "    if pill_count == \"A\": pill_count = np.nan\n",
    "    else: pill_count = int(pill_count)\n",
    "    \n",
    "    meta_df = pd.DataFrame(data={\"pill_count\":[pill_count]})\n",
    "    meta_df[\"pills_low\"] = (meta_df[\"pill_count\"] <= 10).astype(int)\n",
    "    \n",
    "    if type(pill_count) == int:\n",
    "        meta_df[\"activity\"] = \"pill\"\n",
    "    else:\n",
    "        meta_df[\"activity\"] = \"other\"\n",
    "        meta_df[\"pills_low\"] = np.nan\n",
    "        \n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameColumns(df):\n",
    "        \n",
    "    df.columns = ['loggingSample',\n",
    "                   'accel_x',\n",
    "                   'accel_y',\n",
    "                   'accel_z',\n",
    "                   'gyro_x',\n",
    "                   'gyro_y',\n",
    "                   'gyro_z']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimData(df, trim_start_pct, trim_end_pct):\n",
    "    \n",
    "    count = df.shape[0]\n",
    "    new_start = math.floor(count * trim_start_pct)\n",
    "    new_end = math.ceil(count * (1 - trim_end_pct))\n",
    "    \n",
    "    return df[new_start:new_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowData(df, n_windows):\n",
    "    \n",
    "    df[\"window\"] = pd.qcut(df[\"loggingSample\"], \n",
    "                           n_windows, \n",
    "                           range(1,n_windows+1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivotData(df):\n",
    "    \n",
    "    df = df.groupby('window')[[\"gyro_x\", \"gyro_y\", \"gyro_z\", \n",
    "                    \"accel_x\", \"accel_y\", \"accel_z\"]]\\\n",
    "                    .agg([\"median\", \"min\", \"max\", \"std\"])\n",
    "    \n",
    "    df.columns = [\"_\".join(col).strip() for col in df.columns.values]\n",
    "    df[\"temp\"] = None\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df = df.pivot(\"temp\", \"window\").reset_index(drop=True)\n",
    "    df.columns = [col[0] + \"_\" + str(col[1]) for col in df.columns.values]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(path):\n",
    "    \n",
    "    meta_df = getMetaInfo(path)        \n",
    "\n",
    "    df = initializeDf(path)        \n",
    "    df = renameColumns(df)\n",
    "    \n",
    "    if meta_df[\"activity\"][0] == \"other\":\n",
    "        df[\"gyro_z\"] = df[\"gyro_z\"].apply(lambda x: float(x[:-1]))\n",
    "\n",
    "    \n",
    "    df = trimData(df, trim_start_pct=0.05, trim_end_pct=0.05)\n",
    "    df = windowData(df, n_windows=5)\n",
    "    df = pivotData(df)\n",
    "    \n",
    "    \n",
    "    return pd.concat([df, meta_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_df = pd.DataFrame()\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    df_ = processFile(path)\n",
    "    processed_df = pd.concat([processed_df, df_ ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.reset_index(drop=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = processed_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert processed_df.drop([\"pill_count\",\"pills_low\",\"activity\"], axis=1).isna().values.any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Exploratory Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[\"pill_count\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_reg = processed_df.loc[~processed_df.pill_count.isna()]\n",
    "processed_df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_df_reg.drop([\"pill_count\", \"pills_low\", \"activity\"], axis=1).to_numpy()\n",
    "X = ss.fit_transform(X)\n",
    "\n",
    "y = processed_df_reg[[\"pill_count\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel(\"Number of Pills\")\n",
    "plt.ylabel(\"Count\")\n",
    "sns.distplot(y, hist=True, kde=False, bins=31)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Based Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Regressor\n",
    "xgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", n_jobs=-1, n_estimators=150)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "xgb_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(xgb_reg.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much worse on the val data \n",
    "xgb_reg.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_reg.predict(X_val)\n",
    "y_pred[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val[:50].reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "xgb.plot_importance(xgb_reg, max_num_features=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(processed_df_reg.drop([\"pill_count\", \"pills_low\", \"activity\"], axis=1).columns,\n",
    "         xgb_reg.feature_importances_)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg.feature_importances_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "features, scores, med_errors, mean_errors = [], [], [], []\n",
    "\n",
    "thresholds = sorted(xgb_reg.feature_importances_, reverse=True)[:100]\n",
    "#print(thresholds)\n",
    "for thresh in thresholds:\n",
    "    selection = SelectFromModel(xgb_reg, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    n = select_X_train.shape[1]\n",
    "    features += [n]\n",
    "    \n",
    "    selection_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_jobs=-1, n_estimators=100)\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    select_X_val = selection.transform(X_val)\n",
    "    y_pred = selection_model.predict(select_X_val)\n",
    "    \n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    scores += [r2]\n",
    "    \n",
    "    mae = median_absolute_error(y_val, y_pred)\n",
    "    med_errors += [mae]\n",
    "    \n",
    "    mean_error = mean_absolute_error(y_val, y_pred)\n",
    "    mean_errors += [mean_error]\n",
    "    \n",
    "    print(f'Thresh={thresh:.3f}, n={n}, R2: {r2:.2f}, MAE: {mae:.1f}, MeanAE: {mean_error:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(features, scores, linewidth=2, color=\"dodgerblue\")\n",
    "plt.xlabel(\"num top features included\")\n",
    "plt.ylabel(\"val R2 score\")\n",
    "plt.title(\"Feature Selection Model Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(features, med_errors, linewidth=2, color=\"teal\")\n",
    "plt.plot(features, mean_errors, linewidth=2, color=\"red\")\n",
    "plt.xlabel(\"num top features included\")\n",
    "plt.ylabel(\"val MAE\")\n",
    "plt.title(\"Feature Selection Model Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = SelectFromModel(xgb_reg, threshold=thresholds[9], prefit=True)\n",
    "select_X_train = selection.transform(X_train)\n",
    "\n",
    "selection_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_jobs=-1, n_estimators=100)\n",
    "selection_model.fit(select_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_X_val = selection.transform(X_val)\n",
    "y_pred = selection_model.predict(select_X_val)\n",
    "    \n",
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on all data\n",
    "select_X_all = selection.transform(X)\n",
    "select_X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_model.fit(select_X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all = selection_model.predict(select_X_all)\n",
    "\n",
    "r2_score(y, y_pred_all), median_absolute_error(y, y_pred_all), mean_absolute_error(y, y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    " 'max_depth':[2, 3, 4],\n",
    " 'min_child_weight':[1, 2, 3],\n",
    " 'reg_alpha':[0, 0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "searchCV = RandomizedSearchCV(estimator=selection_model,\n",
    "                                 param_distributions=params, \n",
    "                                 n_iter=50,\n",
    "                                 cv=3,\n",
    "                                 verbose=1,\n",
    "                                 n_jobs=-1,)\n",
    "\n",
    "searchCV.fit(select_X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchCV.best_params_, searchCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = searchCV.predict(select_X_all)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually not as good\n",
    "r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a holdout set\n",
    "searchCV_val = RandomizedSearchCV(estimator=xgb_reg,\n",
    "                                  param_distributions=params, \n",
    "                                  n_iter=10,\n",
    "                                  cv=3,\n",
    "                                  verbose=12,\n",
    "                                  n_jobs=-1,)\n",
    "\n",
    "searchCV_val.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchCV_val.best_params_, searchCV_val.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = searchCV_val.predict(X_val)\n",
    "y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scitkit-learn Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "rf_reg.fit(X_train, y_train)\n",
    "rf_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'min_samples_leaf':[3,5,10], \n",
    "          'max_depth':[5,10,15],\n",
    "          'n_estimators':[100,250,500],\n",
    "          'max_features':[\"auto\",\"sqrt\",\"log2\"]\n",
    "          }\n",
    "\n",
    "searchCV = RandomizedSearchCV(estimator=rf_reg,\n",
    "                                  param_distributions=params, \n",
    "                                  n_iter=10,\n",
    "                                  cv=3,\n",
    "                                  verbose=12,\n",
    "                                  n_jobs=-1,)\n",
    "\n",
    "searchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchCV.best_params_, searchCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchCV.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchCV.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(searchCV.predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.05, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer=adam)\n",
    "model.fit(X_train,y_train,epochs=500, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_val).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "\n",
    "y_train = torch.tensor(y_train).float()\n",
    "y_val = torch.tensor(y_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_shape, 32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(32, 16),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(16, 1))\n",
    "\n",
    "epochs = 5000\n",
    "lr = 0.05\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for e in range(epochs+1):\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    y_hat_train = model(X_train)\n",
    "    train_loss = F.mse_loss(y_hat_train.squeeze(1), y_train.flatten())\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(X_val)\n",
    "    val_loss = F.mse_loss(y_hat_val.squeeze(1), y_val.flatten())\n",
    "\n",
    "    if e%500==0: \n",
    "        print(f\"epoch {e}:  train loss: {round(train_loss.item(), 2)} val loss: {round(val_loss.item(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_val).detach().numpy()\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_val.detach().numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_absolute_error(y_val.detach().numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_clf = processed_df.loc[~processed_df.pill_count.isna()]\n",
    "processed_df_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_df_clf.drop([\"pill_count\", \"pills_low\", \"activity\"], axis=1)\n",
    "y_clf = processed_df_clf[[\"pills_low\"]]\n",
    "\n",
    "X_train, X_val, y_train_clf, y_val_clf = train_test_split(ss.fit_transform(X.to_numpy()), y_clf.to_numpy(),\n",
    "                                                          test_size=0.20, random_state=19)\n",
    "y_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "xgb_clf.fit(X_train, y_train_clf)\n",
    "xgb_clf.score(X_train, y_train_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.score(X_val, y_val_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf = xgb_clf.predict(X_val)\n",
    "f1_score(y_val_clf, y_pred_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "\n",
    "y_train_clf = torch.tensor(y_train_clf).float()\n",
    "y_val_clf = torch.tensor(y_val_clf).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_shape, 20),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(20, 50),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(50, 1))\n",
    "\n",
    "epochs = 5000\n",
    "lr = 0.01\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for e in range(epochs+1):\n",
    "       \n",
    "    model.train()\n",
    "    y_hat_train = model(X_train)\n",
    "    train_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_train.squeeze(1)), y_train_clf)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(X_val)\n",
    "    val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val.squeeze(1)), y_val_clf)\n",
    "\n",
    "    if e%500==0: \n",
    "        print(f\"epoch {e}:  train loss: {round(train_loss.item(), 2)} val loss: {round(val_loss.item(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf = torch.sigmoid(model(X_val)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_pred_clf.round(), y_val_clf.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
