{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#GBTRegressor\" data-toc-modified-id=\"GBTRegressor-1\">GBTRegressor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\">Load Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#GBT\" data-toc-modified-id=\"GBT-1.1.1\">GBT</a></span></li><li><span><a href=\"#LOGISTIC\" data-toc-modified-id=\"LOGISTIC-1.1.2\">LOGISTIC</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:25.262928Z",
     "start_time": "2020-02-01T01:01:25.249715Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# SparkML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "# SparkSQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:25.275805Z",
     "start_time": "2020-02-01T01:01:25.270115Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"org.apache.hadoop:hadoop-aws:2.7.4\"  --driver-memory \"4g\" --executor-memory \"4g\" pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:25.288659Z",
     "start_time": "2020-02-01T01:01:25.283988Z"
    }
   },
   "outputs": [],
   "source": [
    "#from pyspark import SparkConf\n",
    "# conf = SparkConf().set(\"spark.driver.memory\", \"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:54.268889Z",
     "start_time": "2020-02-01T01:01:53.284533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the ball rolling\n",
    "sc = SparkContext().getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:57.184357Z",
     "start_time": "2020-02-01T01:01:57.174716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x10a137780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.set(\"spark.driver.memory\", \"6g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:57.199047Z",
     "start_time": "2020-02-01T01:01:57.190504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6g'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.get(\"spark.driver.memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:57.217809Z",
     "start_time": "2020-02-01T01:01:57.207484Z"
    }
   },
   "outputs": [],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', 'AKIAW7CYB6L5SISYOIU7')    # Access Key\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', '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') # Secret Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:59.561703Z",
     "start_time": "2020-02-01T01:01:57.227568Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"s3a://msds-sparkle/data/lite/lite_619.csv\"\n",
    "df_pills = ss.read.csv(data_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:01:59.578105Z",
     "start_time": "2020-02-01T01:01:59.569131Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_pills = ss.read.csv('./lite_629_w10.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:02:01.144401Z",
     "start_time": "2020-02-01T01:01:59.581749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  399|\n",
      "|    0|  220|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pills.groupBy(\"label\").count().show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:02:01.511768Z",
     "start_time": "2020-02-01T01:02:01.147418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 103)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_observations, n_features\n",
    "df_pills.count(), len(df_pills.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:02:24.359029Z",
     "start_time": "2020-02-01T01:02:24.354005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode pill counts less than or equal to 15 as 1, else 0\n",
    "# convert_int = udf(lambda x : float(x <= 10), DoubleType())\n",
    "# df_pills = df_pills.withColumn('label', convert_int('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:02:24.918326Z",
     "start_time": "2020-02-01T01:02:24.366555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cross_val(df_pills, k, pipeline, model_name):\n",
    "    # get the k splits\n",
    "    set_of_k = set(i for i in range(k))\n",
    "    data_splits = df_pills.randomSplit(weights=[1/k for _ in set_of_k])\n",
    "    # instantiate to hold f1s and accuracies\n",
    "    scores = defaultdict(list)\n",
    "    # outer loop to train each of the k models\n",
    "    for i in set_of_k:\n",
    "        # getting test dataset\n",
    "        df_test = data_splits[i]\n",
    "        # splits going into train dataset\n",
    "        train_splits = list(set_of_k - {i})\n",
    "        print(train_splits)\n",
    "        # defining first train set to union rest with\n",
    "        df_train = data_splits[train_splits[0]]\n",
    "        # inner loop to concat the rest of the splits into the train set\n",
    "        for s in train_splits[1:]:\n",
    "                df_train = df_train.union(data_splits[s])\n",
    "        ####  build pipeline and define models\n",
    "        # train model pipeline\n",
    "        start = time.time()\n",
    "        pipeline_model = pipeline.fit(df_train)\n",
    "        print(f\"{model_name} Model {i} training time:\", time.time() - start)\n",
    "        #### predictions and metric\n",
    "        predict = pipeline_model.transform(df_test)\n",
    "        metrics = MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\")\n",
    "        metrics.setMetricName(\"accuracy\")\n",
    "        accuracy = metrics.evaluate(predict)\n",
    "        print(f\"{model_name} Accuracy: {metrics.evaluate(predict):.4f}\")\n",
    "        scores[\"accuracies\"].append(accuracy)\n",
    "        metrics.setMetricName(\"f1\")\n",
    "        f1 = metrics.evaluate(predict)\n",
    "        print(f\"{model_name} F1: {metrics.evaluate(predict):.3f}\")\n",
    "        scores[\"f1s\"].append(f1)\n",
    "        \n",
    "        #### Feature importances\n",
    "        fitted_model = pipeline_model.stages[1]\n",
    "        feat_imps_gbt = fitted_model.featureImportances\n",
    "        top_tups_gbt = sorted(list(zip(feat_imps_gbt.indices, feat_imps_gbt.values)), key=lambda x: x[1], reverse=True)[:5]\n",
    "        top_indices = [x for x in top_tups_gbt[:25]]\n",
    "        top_features = [(df_pills.columns[index[0]], f'{index[1]:.1%}') for index in top_indices]\n",
    "        top_features\n",
    "        print(f\"{model_name} Feature importances:\\n{pd.DataFrame(top_features)}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:02:24.983356Z",
     "start_time": "2020-02-01T01:02:24.921049Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Drop target=\"label\" col from training data\n",
    "train_cols = df_pills.drop(\"label\").columns[1:-1]\n",
    "\n",
    "# Transformer; excludes \"label\" col\n",
    "va = VectorAssembler(outputCol=\"features\", inputCols=train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:07:58.864648Z",
     "start_time": "2020-02-01T01:02:24.986572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "GBT Model 0 training time: 79.24049520492554\n",
      "GBT Accuracy: 0.7863\n",
      "GBT F1: 0.786\n",
      "GBT Feature importances:\n",
      "                           0     1\n",
      "0               4_min_gyro_x  4.5%\n",
      "1  2_avg_audio_average_power  3.3%\n",
      "2               4_max_gyro_x  3.0%\n",
      "3               1_max_gyro_x  3.0%\n",
      "4     4_avg_audio_peak_power  2.8%\n",
      "[0, 2, 3, 4]\n",
      "GBT Model 1 training time: 58.23546814918518\n",
      "GBT Accuracy: 0.7752\n",
      "GBT F1: 0.775\n",
      "GBT Feature importances:\n",
      "                           0     1\n",
      "0               1_max_gyro_x  5.7%\n",
      "1               4_min_gyro_x  3.6%\n",
      "2     4_min_audio_peak_power  3.6%\n",
      "3               0_max_gyro_x  3.2%\n",
      "4  2_avg_audio_average_power  2.6%\n",
      "[0, 1, 3, 4]\n",
      "GBT Model 2 training time: 57.443233013153076\n",
      "GBT Accuracy: 0.8447\n",
      "GBT F1: 0.844\n",
      "GBT Feature importances:\n",
      "                           0     1\n",
      "0  2_avg_audio_average_power  3.8%\n",
      "1               1_max_gyro_x  3.3%\n",
      "2               4_min_gyro_x  3.2%\n",
      "3     3_min_audio_peak_power  2.9%\n",
      "4               4_max_gyro_x  2.9%\n",
      "[0, 1, 2, 4]\n",
      "GBT Model 3 training time: 59.69183802604675\n",
      "GBT Accuracy: 0.7971\n",
      "GBT F1: 0.799\n",
      "GBT Feature importances:\n",
      "                           0     1\n",
      "0               1_max_gyro_x  5.2%\n",
      "1               0_max_gyro_x  4.8%\n",
      "2  0_max_audio_average_power  4.3%\n",
      "3               4_min_gyro_x  3.3%\n",
      "4     2_min_audio_peak_power  3.3%\n",
      "[0, 1, 2, 3]\n",
      "GBT Model 4 training time: 57.85104417800903\n",
      "GBT Accuracy: 0.7458\n",
      "GBT F1: 0.746\n",
      "GBT Feature importances:\n",
      "                        0     1\n",
      "0            1_max_gyro_x  4.4%\n",
      "1            0_max_gyro_x  3.5%\n",
      "2            3_max_gyro_x  3.1%\n",
      "3  3_min_audio_peak_power  3.0%\n",
      "4            4_max_gyro_x  3.0%\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Estimator\n",
    "gbt = GBTClassifier(maxIter=200, maxDepth=3, stepSize=0.3)\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "gbt_pipeline = Pipeline(stages=[va, gbt])\n",
    "scores = cross_val(df_pills, 5, gbt_pipeline, 'GBT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:08:24.851726Z",
     "start_time": "2020-02-01T01:07:58.867335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "LR Model 0 training time: 22.835731983184814\n",
      "LR Accuracy: 0.6949\n",
      "LR F1: 0.693\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionModel' object has no attribute 'featureImportances'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a99b4d7ba3a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the pipeline to training documents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-48f175aab617>\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m(df_pills, k, pipeline, model_name)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#### Feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mfeat_imps_gbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureImportances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mtop_tups_gbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_imps_gbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_imps_gbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_tups_gbt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionModel' object has no attribute 'featureImportances'"
     ]
    }
   ],
   "source": [
    "# Estimator\n",
    "lr = LogisticRegression(maxIter=1500, fitIntercept=True)\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "lr_pipeline = Pipeline(stages=[va, lr])\n",
    "scores = cross_val(df_pills, 5, lr_pipeline, 'LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
